<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title></title>
		<meta name='Generator' content='Zim 0.60'>
		<style type='text/css'>
			a          { text-decoration: none      }
			a:hover    { text-decoration: underline }
			a:active   { text-decoration: underline }
			strike     { color: grey                }
			u          { text-decoration: none;
			             background-color: yellow   }
			tt         { color: #2e3436;            }
			pre        { color: #2e3436;
			             margin-left: 20px          }
			h1         { text-decoration: underline;
			             color: #4e9a06             }
			h2         { color: #4e9a06             }
			h3         { color: #4e9a06             }
			h4         { color: #4e9a06             }
			h5         { color: #4e9a06             }
			span.insen { color: grey                }
		</style>
	</head>
	<body>

<!-- Header -->

	[ <a href='./MultiThreadingTechniques/Volatile.html'>Prev</a> ]

			[ <a href='./index.html.html'>Index</a> ]

	[ <a href='./NeuralNetworks/Appendix.html'>Next</a> ]

<!-- End Header -->

<hr />

<!-- Wiki content -->

<h1>NeuralNetworks</h1>

<p>
Created Friday 15 November 2013<br>
</p>

<h2>Definition of a Neuron</h2>
<p>
A <strong>neuron</strong> N is a pair `(bb w, phi)`, where `bb w` is the bias plus a list of `k` weights `(w_0, w_1,... , w_k)` and `phi` is an <a href="./NeuralNetworks/ActivationFunction.html" title="activation function" class="page">activation function</a>. We call `w_0` the bias weight. (Note: alternatively, we can put the bias at the end of the list. We would just need to redefine `x_0` accordingly. See below.)<br>
</p>

<p>
If `v_N: RR^(k+1) -&gt; RR` is defined as<br>
</p>

<p>
`\ v_N(bb x) = bb w * bb x = bb sum_i^k w_i x_i`<br>
</p>

<p>
then the value of `v_N` at a specific `bb x` is called the <strong>induced local field </strong>of neuron N.<br>
</p>

<p>
The <strong>impulse function</strong> of a neuron N, which we will denote `f_N: RR^(k+1) -&gt; (0,1)`, is defined as<br>
</p>

<p>
`f_N(bb x) = phi(v_N(bb x)) = phi(bb w * bb x)`<br>
</p>

<p>
By convention, `x_0` (which is mapped to the bias) is fixed at 1 for all inputs `bb x`.<br>
</p>

<h3>Purpose of the Bias</h3>
<p>
A single neuron basically separates data with a line (or in general, a hyper plane). The bias allows for lines that do not pass through the origin. <br>
</p>

<h2>Definition of a Neural Network</h2>
<p>
A <strong>neural network </strong>can be thought of as a function that is itself the composition, sum, and product of impulse functions. See <a href="http://en.wikibooks.org/wiki/Artificial_Neural_Networks/Neural_Network_Basics" title="here" class="http">here</a> for diagrams or take a look at the <a href="./NeuralNetworks/Resources.html" title="resources." class="page">resources.</a> More importantly, since `phi` is continuous and differentiable, the function representing the neural network is itself continuous and differentiable. <br>
</p>
 



<!-- End wiki content -->

<hr />

<!-- Attachments and Backlinks -->

	<b>Backlinks:</b>		<a href='./NeuralNetworks/BackPropagation.html'>NeuralNetworks:BackPropagation</a>
<br><br>

	<b>Attachments:</b>
	<table>		<tr><td><a href='./NeuralNetworks/ActivationFunction'>ActivationFunction</a></td><td>&nbsp;</td><td>4.10kb</td></tr>		<tr><td><a href='./NeuralNetworks/Appendix'>Appendix</a></td><td>&nbsp;</td><td>4.10kb</td></tr>		<tr><td><a href='./NeuralNetworks/BackPropagation'>BackPropagation</a></td><td>&nbsp;</td><td>4.10kb</td></tr>	</table>

<!-- End Attachments and Backlinks -->
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'beardedandroid'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.

	</body>

</html>
