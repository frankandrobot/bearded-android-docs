Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2013-12-07T18:07:25-05:00

====== Parameters ======
Created Saturday 07 December 2013

The backpropagation algorithm works by adjusting the weights with the learning and momentum terms:

`\ w_(kj)^((l)) = w_(kj)^((l)) + alpha w_(kj)^(**(l)) + eta sum_i sigma_k^((l))(i) y_j^((l-1))(i)`

where 
* `w_(kj)^((l))` is a weight connecting neuron `N_k` in layer `l` to neuron `N_j` in the previous layer
* `w_(kj)^(**(l))` is the //previous //value of the weight
* `alpha` is called the **momentum parameter**
* `eta` is called the **learning parameter**
* the sum `sum_i` is over all the training examples
* `sigma_k^((l))(i)` is the gradient of neuron `N_k^((l))` when the network is fed input `bb x(i)`
* `y_j^((l-1))(i)` is the input fed to layer `l` when the network is fed input `bb x(i)`. See [[BackPropagation|back propagation implementation.]]
 
Unfortunately, networks can not learn using arbitrary learning and momentum parameters. You might think that the implementation is broken but you’re just using the wrong parameters. So develop an intuitive understanding of these parameters:

* start with a simple two-layer network and train it to learn one example. Explore how the parameters affect the rate of learning or whether the network learns at all. 
* Repeat with two examples. 

In general, you’ll find that difficult problems require a smaller learning parameter (but that increases the number of iterations of the backpropagation algorithm required). The momentum keeps the network from getting stuck but if its too large then it also keeps the network from learning.

Note that not all versions of the backpropagation algorithm are created equal. The classical [[BatchModeBackPropagation]] algorithm is very sensitive to these parameters, while other versions such as the [[StochasticGradientBackPropagation]] are more robust.
