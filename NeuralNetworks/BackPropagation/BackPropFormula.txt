Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2014-07-16T01:05:13-05:00

====== BackPropFormula ======
Created Wednesday 16 July 2014

As per the [[Motivation]] page, the network "learns" by minimizing the [[ErrorFunction|error function]] via incrementally adjusting the weights until the actual output is close to the expected output. Apply the **backpropagation formula** to adjust the weights in each iteration of the //backpropagation algorithm //until the total error is less than a predetermined value.

===== Notation =====
* Please read the [[Notation|notation page]]

===== The Formula =====
`\ w_(kj)^((l)) = w_(kj)^((l)) + alpha w_(kj)^(**(l)) + sum_i Delta w_(kj)^((l))[i]`
`\ \ \ \ = w_(kj)^((l)) + alpha w_(kj)^(**(l)) + eta sum_i delta_k^((l))[i] y_j^((l-1))[i]`

Before you implement your own version of the backprop algorithm, check out the [[Motivation]] and [[BatchModeBackPropagation]] for implementation tips and gotchas.
