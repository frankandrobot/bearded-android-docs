Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2014-01-07T14:13:20-05:00

====== Neuron ======
Created Tuesday 07 January 2014

There are actually several types of neurons but the most important is the //sigmoid neuron//:

* sigmoid neuron
* radial neuron

===== Sigmoid Neuron =====
The type of neuron most frequently used is the **sigmoid neuron**, defined as a pair `(bb w, phi)`:

* The weights `bb w` consist of the bias plus a list of `k` weights `(w_0, w_1,... , w_k)`. We call `w_0` the bias weight. (Note: alternatively, we can put the bias at the end of the list. We would just need to redefine `x_0` accordingly. See below.)
* `phi` is an [[ActivationFunction|activation function]]. 

To define the output of a neuron, first define the **induced local field **`v_N(bb x)` of neuron //N //at input `bb x`//://

* `v_N(bb x) = bb w * bb x = sum_i^k w_i x_i` where `v_N` is a function from `RR^(k+1)` to `RR`.

**Note: **the induced local field is //not //a function; it's the value of `v_N` at a specfic `bb x`. 

The output of a neuron is given by its **impulse function**, which we will denote `f_N: RR^(k+1) -> (0,1)`:

* `f_N(bb x) = phi(v_N(bb x)) = phi(bb w * bb x)`

**Note:** By convention, `x_0` (which is mapped to the bias) is fixed at 1 for all inputs `bb x`.

==== Purpose of the Bias ====
A neuron with a two weights separates 2D data with a line (or in general, a hyper plane). The bias allows for lines (or hyper planes) that do not pass through the origin. 

===== Radial Neurons =====
A **radial neuron** uses a Euclidian radial basis function (RBF) instead of an activation function. If the weights are `(w_1,... , w_k)`, then the output is

`\ f_N(bb x) = sum_j (x_j - w_j)^2`

In other words, each RBF neuron computes the Euclidian distance between the input and its weight vector. The farther away the input from the weight, the larger the output. 

If the input represents an object and a radial neuron represents a class of objects, then its output represents a penalty term measuring the fit between the input and the class.



