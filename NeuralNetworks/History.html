<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>History</title>
		<meta name='Generator' content='Zim 0.60'>
		<style type='text/css'>
			a          { text-decoration: none      }
			a:hover    { text-decoration: underline }
			a:active   { text-decoration: underline }
			strike     { color: grey                }
			u          { text-decoration: none;
			             background-color: yellow   }
			tt         { color: #2e3436;            }
			pre        { color: #2e3436;
			             margin-left: 20px          }
			h1         { text-align: center;
			             color: #4e9a06             }
			h2         { color: #4e9a06             }
			h3         { color: #4e9a06             }
			h4         { color: #4e9a06             }
			h5         { color: #4e9a06             }
			span.insen { color: grey                }
			.page { max-width: 1000px;}
			.menu{
				float:left; width: 300px;
			}

			.content { padding-left: 320px;}
			.notebook{font-variant: small-caps;
					color:#4e9a06;
					padding: 0px 20px;}
			hr{clear:both;}
		</style>
		<script type="text/javascript"
		   src="http://cdn.mathjax.org/mathjax/2.3-latest/MathJax.js?config=AM_HTMLorMML.js">
		</script>


	</head>
	<body>
		<div class="page">
			<div class="heading">
									<h1>History</h1>
			</div>
			<hr>
			<div class="menu">
				<ul>
<li><a href="../ActiveMQ.html" title="ActiveMQ" class="page">ActiveMQ</a></li>
<li><a href="../Android.html" title="Android" class="page">Android</a></li>
<li><a href="../ContextFreeGrammar.html" title="ContextFreeGrammar" class="page">ContextFreeGrammar</a></li>
<li><a href="../Database.html" title="Database" class="page">Database</a></li>
<li><a href="../Help.html" title="Help" class="page">Help</a></li>
<li><a href="../HttpProtocol.html" title="HttpProtocol" class="page">HttpProtocol</a></li>
<li><a href="../Java.html" title="Java" class="page">Java</a></li>
<li><a href="../JavaMemory.html" title="JavaMemory" class="page">JavaMemory</a></li>
<li><a href="../JavaScript.html" title="JavaScript" class="page">JavaScript</a></li>
<li><a href="../MultiThreading.html" title="MultiThreading" class="page">MultiThreading</a></li>
<li><a href="../MultiThreadingTechniques.html" title="MultiThreadingTechniques" class="page">MultiThreadingTechniques</a></li>
<li><a href="../NETFramework.html" title="NETFramework" class="page">NETFramework</a></li>
<li><a href="../NeuralNetworks.html" title="NeuralNetworks" class="page">NeuralNetworks</a></li>
<ul>
<li><a href="./ActivationFunction.html" title="ActivationFunction" class="page">ActivationFunction</a></li>
<li><a href="./Appendix.html" title="Appendix" class="page">Appendix</a></li>
<li><a href="./BackPropagation.html" title="BackPropagation" class="page">BackPropagation</a></li>
<li><a href="./ConvolutionalNetwork.html" title="ConvolutionalNetwork" class="page">ConvolutionalNetwork</a></li>
<li><strong class="activepage">History</strong></li>
<li><a href="./Neuron.html" title="Neuron" class="page">Neuron</a></li>
<li><a href="./Resources.html" title="Resources" class="page">Resources</a></li>
</ul>
<li><a href="../OOP.html" title="OOP" class="page">OOP</a></li>
<li><a href="../TODO.html" title="TODO" class="page">TODO</a></li>
<li><a href="../UnitTests.html" title="UnitTests" class="page">UnitTests</a></li>
</ul>

			</div>
			<div class="content">
			<!-- Wiki content -->
				<p>
Created Tuesday 31 December 2013<br>
</p>

<p>
Two neural networks are at a bar. One says to the  other, "Hey, I learned that if A then B". The other replies, "Wow, I know that if B then C". "Why don't we teach ourselves if A then C?" A while later, they ask each other "What was it what we were talking about?"<br>
</p>

<p>
The joke is in reference to the fact that while neural networks can be used to create powerful technologies (self-driving car, voice recognition like Google Now, etc), neural networks are actually pretty stupid. The reality is that machine learning hasn't advanced much when it comes to creating a machine that can actually think for itself i.e., "sentient" artificial intelligence. <br>
</p>

<p>
As per <a href="http://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing.html" title="this TED talk" class="http">this TED talk</a>, the real problem is that there doesn't seem to be a common "theory of learning."<br>
</p>

<h2>Why Neural Networks?</h2>

<p>
<a href="../NeuralNetworks.html" title="Neural networks" class="page">Neural networks</a> (NNs) are easy to understand conceptually and (somewhat) easy to code. A strong math background is also required.<br>
</p>

<p>
NNs are good at these types of problems:<br>
</p>

<p>
<ul>
<li><strong>Classification</strong> - the goal is to assign the input object to a predetermined class or group. We provide input objects that are representative of all groups (training examples). NN deduces classification rules from training examples. Ex: handwriting recognition </li>
<li><strong>Prediction</strong> - ex: sun cycles</li>
<li><strong>Clustering (data mining)</strong> - Similar to classification. However, we don't provide the representative groups. The goal is to figure out the groups that partition the training example. Ex: learn characters in an alien language from sample writings. (This is a type of <em>unsupervised learning</em>.)</li>
<li><strong>Pattern Association</strong> - pick out faces from blurry photographs</li>
<li><strong>Optimization</strong> - minimizing or maximizing a function</li>
</ul>
</p>

<p>
In general, NNs are good at <em>bottom-up learning</em>. In contrast, to top-down learning, in bottom-up learning, hard and fast rules either don't exist or are too complicated to express. Real world example: the rules managers use to distribute work at a customer service center. (Managers may not be able to completely verbalize what they do.) <br>
</p>

<h2>A Brief History</h2>

<p>
<ul>
<li>Neurons were researched over 100 years ago. Scientists discovered that our brain is made up of millions of connected neurons.</li>
<li>first mathematical model of a neuron was created in 1943 by Warren McCulloch and Walter Pitts </li>
<li>The original neuron model is basically a linear function. Each coordinate is multiplied by a weight and the sum of each product is the output of the neuron.</li>
<li>Neurons working together in parallel is a <em>single layer of a neural network</em>. Layers can be stacked together to create <em>multi-layer neural networks</em>. </li>
<li>By the 60s, NNs had a lot of hype---robotic servants, etc.</li>
<li>A book in 1969 by Minsky helped destroy interest in neural networks for the next decade. </li>
<li>Minksy pointed out the elephant in the room. Single layer neural networks can model only linear data. </li>
<li>Research decreased during the 70s because: (1) computers weren't (yet) powerful enough for research and (2) no motivation or $money$ (thanks to Minksy)</li>
<li>It wasn't until the 80's that interest in NNs surged again. In particular, the <a href="./BackPropagation.html" title="backpropagation algorithm" class="page">backpropagation algorithm</a> was popularized by Rumelhart. (Up until this point, there was no obvious way to automatically train an NN with sample data.)</li>
</ul>
</p>

<h2>Different Types of NNs</h2>

<p>
There are actually different types of NNs suitable for different types of problems:<br>
</p>

<p>
<ul>
<li><strong>recursive neural networks</strong> - sentiment analysis (natural language processing)</li>
<li><a href="./ConvolutionalNetwork.html" title="convolution networks" class="page">convolution networks</a> - image processing</li>
<li>many more</li>
</ul>
</p>

<h2>The Backpropagation Algorithm</h2>

<p>
The backpropagation algorithm is a popular way of training neural networks. The basic form is described <a href="./BackPropagation/BatchModeBackPropagation.html" title="here" class="page">here</a>.  <br>
</p>

<p>
<ul>
<li>The backpropagation algorithm is a form of <em>supervised learning</em> because you supply the examples.</li>
<li>Its called "backprop" because it starts from the output layer and recursively works backwards to the input layer.</li>
<li>We make one small change to the neuron model in order for the backprop algorithm to be guaranteed to work---apply an <a href="./ActivationFunction.html" title="activation function" class="page">activation function</a> to the output of the neuron. (A commonly used one is <code>tanh</code>. Activation functions have certain math properties that allow the math to work.)</li>
<li>The algorithm reduces the error one small step at a time. It iteratively travels along the direction of highest slope until error is less than given value.</li>
<li>The problem is that we don't know if we reached a local minimum or a global minimum. Theoretically, the algorithm can get stuck even when you add a correction term. However, it doesn't in practice and scientists aren't really sure why.</li>
</ul>
</p>

<h2>Some Resources</h2>

<p>
<ul>
<li><a href="http://jeremykun.com/2011/08/11/the-perceptron-and-all-the-things-it-cant-perceive/" title="http://jeremykun.com/2011/08/11/the-perceptron-and-all-the-things-it-cant-perceive/" class="http">http://jeremykun.com/2011/08/11/the-perceptron-and-all-the-things-it-cant-perceive/</a></li>
<li><a href="http://www.cogsci.rpi.edu/~rsun/sun-zhang-jcsr2004-f.pdf" title="http://www.cogsci.rpi.edu/~rsun/sun-zhang-jcsr2004-f.pdf" class="http">http://www.cogsci.rpi.edu/~rsun/sun-zhang-jcsr2004-f.pdf</a></li>
<li><a href="http://www-cs-faculty.stanford.edu/~eroberts/courses/soco/projects/neural-networks/History/history1.html" title="http://www-cs-faculty.stanford.edu/~eroberts/courses/soco/projects/neural-networks/History/history1.html" class="http">http://www-cs-faculty.stanford.edu/~eroberts/courses/soco/projects/neural-networks/History/history1.html</a></li>
<li><em>Elements of Artificial Neural Networks</em>. Kishan Mehrotra, Chilukuri K. Mohan and Sanjay Ranka</li>
</ul>
</p>


			<!-- End wiki content -->
			</div>
			<hr>
			<!-- Backlinks -->
			<div class="footer">
									<i>No backlinks to this page.</i>
				<br><br>

				
			<!-- End Backlinks -->
			</div>
		</div>
	</body>
</html>
