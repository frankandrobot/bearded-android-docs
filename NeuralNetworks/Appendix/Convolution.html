<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Convolution</title>
		<meta name='Generator' content='Zim 0.60'>
		<style type='text/css'>
			a          { text-decoration: none      }
			a:hover    { text-decoration: underline }
			a:active   { text-decoration: underline }
			strike     { color: grey                }
			u          { text-decoration: none;
			             background-color: yellow   }
			tt         { color: #2e3436;            }
			pre        { color: #2e3436;
			             margin-left: 20px          }
			h1         { text-align: center;
			             color: #4e9a06             }
			h2         { color: #4e9a06             }
			h3         { color: #4e9a06             }
			h4         { color: #4e9a06             }
			h5         { color: #4e9a06             }
			span.insen { color: grey                }
			.page { max-width: 1000px;}
			.menu{
				float:left; width: 300px;
			}

			.content { padding-left: 320px;}
			.notebook{font-variant: small-caps;
					color:#4e9a06;
					padding: 0px 20px;}
			hr{clear:both;}
		</style>
		<script type="text/javascript"
		   src="http://cdn.mathjax.org/mathjax/2.3-latest/MathJax.js?config=AM_HTMLorMML.js">
		</script>


	</head>
	<body>
		<div class="page">
			<div class="heading">
									<h1>Convolution</h1>
			</div>
			<hr>
			<div class="menu">
				<ul>
<li><a href="../../ActiveMQ.html" title="ActiveMQ" class="page">ActiveMQ</a></li>
<li><a href="../../Android.html" title="Android" class="page">Android</a></li>
<li><a href="../../ContextFreeGrammar.html" title="ContextFreeGrammar" class="page">ContextFreeGrammar</a></li>
<li><a href="../../Database.html" title="Database" class="page">Database</a></li>
<li><a href="../../Help.html" title="Help" class="page">Help</a></li>
<li><a href="../../HttpProtocol.html" title="HttpProtocol" class="page">HttpProtocol</a></li>
<li><a href="../../Java.html" title="Java" class="page">Java</a></li>
<li><a href="../../JavaMemory.html" title="JavaMemory" class="page">JavaMemory</a></li>
<li><a href="../../JavaScript.html" title="JavaScript" class="page">JavaScript</a></li>
<li><a href="../../MultiThreading.html" title="MultiThreading" class="page">MultiThreading</a></li>
<li><a href="../../MultiThreadingTechniques.html" title="MultiThreadingTechniques" class="page">MultiThreadingTechniques</a></li>
<li><a href="../../NETFramework.html" title="NETFramework" class="page">NETFramework</a></li>
<li><a href="../../NeuralNetworks.html" title="NeuralNetworks" class="page">NeuralNetworks</a></li>
<ul>
<li><a href="../ActivationFunction.html" title="ActivationFunction" class="page">ActivationFunction</a></li>
<li><a href="../Appendix.html" title="Appendix" class="page">Appendix</a></li>
<ul>
<li><a href="./ChainRule.html" title="ChainRule" class="page">ChainRule</a></li>
<li><strong class="activepage">Convolution</strong></li>
<li><a href="./CriticalPoint.html" title="CriticalPoint" class="page">CriticalPoint</a></li>
<li><a href="./EigenValues.html" title="EigenValues" class="page">EigenValues</a></li>
<li><a href="./EuclidianDistance.html" title="EuclidianDistance" class="page">EuclidianDistance</a></li>
<li><a href="./GaussianDistribution.html" title="GaussianDistribution" class="page">GaussianDistribution</a></li>
<li><a href="./Gradient.html" title="Gradient" class="page">Gradient</a></li>
<li><a href="./HessianMatrix.html" title="HessianMatrix" class="page">HessianMatrix</a></li>
<li><a href="./Jacobian.html" title="Jacobian" class="page">Jacobian</a></li>
<li><a href="./LagrangeMultipliers.html" title="LagrangeMultipliers" class="page">LagrangeMultipliers</a></li>
<li><a href="./VectorFunction.html" title="VectorFunction" class="page">VectorFunction</a></li>
</ul>
<li><a href="../BackPropagation.html" title="BackPropagation" class="page">BackPropagation</a></li>
<li><a href="../ConvolutionalNetwork.html" title="ConvolutionalNetwork" class="page">ConvolutionalNetwork</a></li>
<li><a href="../History.html" title="History" class="page">History</a></li>
<li><a href="../Neuron.html" title="Neuron" class="page">Neuron</a></li>
<li><a href="../Resources.html" title="Resources" class="page">Resources</a></li>
</ul>
<li><a href="../../OOP.html" title="OOP" class="page">OOP</a></li>
<li><a href="../../TODO.html" title="TODO" class="page">TODO</a></li>
<li><a href="../../UnitTests.html" title="UnitTests" class="page">UnitTests</a></li>
</ul>

			</div>
			<div class="content">
			<!-- Wiki content -->
				<p>
Created Friday 13 December 2013<br>
</p>

<p>
<em>Convolution </em>is a term taken from image processing: from a large array of values, take smaller rectangular patches, treat each as inputs to a single neuron, and store the outputs in a smaller array. <br>
</p>

<p>
A picture says 1,000 words: <a href="http://ufldl.stanford.edu/tutorial/index.php/File:Convolution_schematic.gif" title="http://ufldl.stanford.edu/tutorial/index.php/File:Convolution_schematic.gif" class="http">http://ufldl.stanford.edu/tutorial/index.php/File:Convolution_schematic.gif</a><br>
</p>

<p>
<ul>
<li>Let `X_n` be an `n xx n` matrix of real-number values.</li>
<li>Let `X_s` be a smaller matrix of size `(n-s+1) xx (n-s+1)` called a <strong>feature map </strong>that will be created by sampling patches of size `s xx s` from the larger matrix.</li>
<li>Each unit (or cell) of `X_s` has a corresponding neuron `(sigma, bb W, b)` where `sigma` is the activation function, `bb W` is the set of weights, and `b` is the bias. </li>
<li>`bb W` has `s^2` weights: `bb W = (w_1, ... w_(s^2))`.</li>
<li>The weights are also called the <strong>kernels</strong>. The set of weights `bb W` is called the <strong>kernel</strong>.</li>
<li>The <strong>receptive field size</strong> of the neuron is `s^2`. </li>
<li><strong>The neurons all share the same weights </strong>i.e., there is a single set of weights for `X_s`.</li>
</ul>
</p>

<p>
To calculate the values of `X_s`:<br>
<ul>
<li>Let `x_s(i,j)` be the value of `X_s` at position `(i,j)` (row i, column j).</li>
<li>Let `x_n(i,j)` be the value of `X_n` at position `(i,j)` (row i, column j).</li>
<li>Let patch `P_s(i,j)` be the sub-array of values of `X_n` of size `s xx s` and top-left corner `(i, j)`. `P_s(i,j)` is a square matrix:</li>
</ul>
</p>

<p>
`\ \ \ \ P_s(i,j) <br>
= [(x_n(i,j),x_n(i,j+1),...,x_n(i,j+s))<br>
,(x_n(i+1,j),x_n(i+1,j+1),...,x_n(i+1,j+s))<br>
,(vdots, vdots, vdots, vdots)<br>
,(x_n(i+s,j),x_n(i+s,j+1),...,x_n(i+s,j+s))]`<br>
</p>

<p>
Even though `P_s(i,j)` is a matrix, think of it as a "flattened" vector of size `s^2`:<br>
</p>

<p>
`\ \ bb P_s(i,j) = (x_n(i,j),x_n(i,j+1),...,x_n(i,j+s),...,x_n(i+s,j),x_n(i+s,j+1),...,x_n(i+s,j+s))`<br>
</p>

<p>
Define `x_s(i,j)` as:<br>
</p>

<p>
`\ \ x_s(i,j) = sigma(bb P_(ns)(i,j) * bb W + b)`<br>
</p>

<p>
Construction of feature map `X_s` <em>without</em> <em>applying the activation function `sigma`</em> <em>or the bias</em> is called <strong>convolution with kernel </strong>`bb W` (i.e., if `X'_s` is defined as `x'_s(i,j) = bb P_(ns)(i,j) * bb W`, then `X'_s` is the convolution of kernel `bb W`).<br>
</p>

<h2>Resources</h2>
<p>
<ul>
<li><a href="http://www.mathworks.com/help/vision/ref/2dconvolution.html" title="http://www.mathworks.com/help/vision/ref/2dconvolution.html" class="http">http://www.mathworks.com/help/vision/ref/2dconvolution.html</a></li>
</ul>
</p>


			<!-- End wiki content -->
			</div>
			<hr>
			<!-- Backlinks -->
			<div class="footer">
									<i>No backlinks to this page.</i>
				<br><br>

				
			<!-- End Backlinks -->
			</div>
		</div>
	</body>
</html>
